---
title: Kafka学习
date: 2022-09-24 21:15:45
permalink: /pages/c858bf/
categories:
  - 中间件
  - 消息队列
tags:
  - 
author: 
  name: Marvel
  link: https://github.com/zouquchen
---
# Kafka 学习

::: tip 学习中

:::

## 1. Kafka概念

Kafka 传统定义：是一个**分布式**的基于**发布/订阅模式**的**消息队列**，主要应用于大数据实时处理领域。

kafka 最新定义：开源的**分布式事件流平台**，用于高性能**数据管道 、流分析、数据集成和关键任务**应用。

> 野心非常大，不甘心只做消息队列

发布/订阅：消息的发布者不会将消息直接发送给特定的订阅者，而是**将发布的消息分为不同的类别**，订阅者**只接收感兴趣的消息**。

在大数据库场景主要采用 KafKa，JavaEE 开发中采用 ActiveMQ、RabbitMQ、RocketMQ

⭐ 消息队列作用：削峰、异步、解耦

⭐ 消息队列模式

- 点对点模式：消费者主动拉取数据，消息成功消费后清除消息
- 发布/订阅模式：可以有多个 topic 主题，每个消费者相互独立，消费者消费数据后不删除数据

## 2. Kafka 基础架构

1. 为方便扩展，提高吞吐量，一个 topic 分为多个 partition
2. 配合分区的设计，提出消费者组的概念，组内每个消费者并行消费
   - 一个分区 partition，只能由一个消费者消费。如果由多个消费者不利于消息的管理
3. 为提高可用性，为每个 partition  增加若干副本
   - 分为 leader & follower，只针对于 leader 进行生产和消费
   - 只有 leader 挂掉后 follower 才能成为 leader，才能进行生产和消费
4. Zookeeper 管理 Kafka 集群
   - 记录在线的 broker 
   - 记录 partitions 中的 leader

![Kafka](https://raw.githubusercontent.com/zouquchen/Images/main/imgs2022/Kafka-architecture.png)

- Producer：生产者，负责将客户端生产的消息发送到 Kafka 中，可以支持消息的异步发送和批量发送；
- broker：服务代理节点，Kafka 集群中的一台服务器就是一个 broker，可以水平无限扩展，同一个 Topic 的消息可以分布在多个 broker 中；
- Consumer：消费者，通过连接到 Kafka 上来接收消息，用于相应的业务逻辑处理。
  ZooKeeper：管理 Kafka 集群
- Consumer Group：消费者组，指的是多个消费者共同组成一个组来消费一个 Topic 中的消息。



## 3. Kafka 重要概念

⭐ **Topic 与 Partition**

在 Kafka 中消息是以 Topic 为单位进行归类的，Topic 在逻辑上可以被认为是一个 Queue，Producer 生产的每一条消息都必须指定一个 Topic，然后 Consumer 会根据订阅的 Topic 到对应的 broker 上去拉取消息。

为了提升整个集群的吞吐量，Topic 在物理上还可以细分多个分区，一个分区在磁盘上对应一个文件夹。由于一个分区只属于一个主题，很多时候也会被叫做主题分区(Topic-Partition)。

⭐ **Leader 和 Follower**

一个分区会有多个副本，副本之间是一主(Leader)多从(Follower)的关系，Leader 对外提供服务，这里的对外指的是与客户端程序进行交互，而 Follower 只是被动地同步 Leader 而已，不能与外界进行交互。

当然了，你可能知道在很多其他系统中 Follower 是可以对外提供服务的，比如 MySQL 的从库是可以处理读操作的，但是在 Kafka 中 Follower 只负责消息同步，不会对外提供服务。

⭐ **Kafka 多副本机制**

Kafka 为分区引入了多副本机制，同一分区的不同副本中保存的信息是相同的，通过多副本机制实现了故障的自动转移，当集群中某个 broker 失效时仍然能保证服务可用，可以提升容灾能力。

## 4. 安装使用

### 4.1 安装部署  

#### 4.1.1 集群规划

我的虚拟机里面由 3 个 CentOS 系统，所以规划为：

| 101   | 102   | 103   |
| ----- | ----- | ----- |
| zk    | zk    | zk    |
| kafka | kafka | kafka |

每一台机器内都安装 zookeeper 和 kafka，我这里为了方便就只在 103 内配置了 zk。

#### 4.1.2 集群部署

**步骤0**：配置 zk 集群，也可以单机

**步骤1**：[下载](https://kafka.apache.org/downloads)

![image-20220925095359505](https://raw.githubusercontent.com/zouquchen/Images/main/imgs2022/kafka-download.png)

2.12 版本指 Scale 版本，3.0.0 版本指 Kafka 版本。

**步骤2**：解压 `tar -zxvf kafka_2.12-3.0.0.tgz`

**步骤3**：重命名 `mv kafka_2.12-3.0.0 kafka`，把解压后的文件名改为 kafka

**步骤4**：配置 `kafka/config/server.properties`

```properties
# kafka 集群中身份唯一表示，三个 broker 分别配置 0 1 2
broker.id=0

# 存储 kafka 数据，默认放在 temp 中，会被定期清理
log.dirs=/opt/kafka/datas

# 配置 zk 集群，/kafka 表示都在 kafka 节点上，后面需要找个集群时可以直接删掉
# zookeeper.connect=192.168.150.101:2181,192.168.150.102:2181,192.168.150.103:2181/kafka
# 也可以不使用集群，就配置个单机
zookeeper.connect=192.168.150.103:2181/kafka
```

分别配置 3 个 kafka，注意 broker.id 要不同。

**步骤5**：配置环境变量

`vim /etc/profile.d/my_env.sh`

为每个节点，添加以下内容：

```sh
#KAFKA_HOME
export KAFKA_HOME=/opt/kafka
export PATH=$PATH:$KAFKA_HOME/bin
```

刷新：`source /etc/profile`

**步骤6**：启动 zookeeper

**步骤7**：启动 kafka

`kafka-server-start.sh -daemon config/server.properties`
