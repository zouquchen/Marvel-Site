---
title: 海量数据处理
date: 2022-08-03 15:00:48
permalink: /pages/1dd8bd/
categories:
  - Java
  - 常见面试题
tags:
  - 
author: 
  name: Marvel
  link: https://github.com/zouquchen
---

# 海量数据处理

## 1 如何从大量 URL 中找出相同的 URL ？

**题目描述**

给定 a、b 两个文件，各存放 50 亿个 URL，每个 URL 各占 64B，内存限制是 4G。请找出 a、b 两个文件共同的 URL。

**解答思路**

> 50 亿个 64B 的 URL 共占用 620 G 空间，如果把他分成 1000 份，平均每份 320 M，就可以放入内存中。

采用分治策略，逐步读取遍历 a 文件，对遍历到的 URL 求 `hash(URL) % 1000`，根据不同的结果存储在不同的文件 a0, a1, a2, ... 中，这样大概就会有 1000 份文件。对 b 文件采用相同的方法，得到 b0, b1, b2, ... 

接着遍历ai，把 URL 存储到一个 HashSet 中，然后再遍历 bi 中的每一个 URL，查看 HashSet 集合中是否存在。

## 2 如何从大量数据中找出高频词？

**题目描述**

有一个 1GB 大小的文件，文件里每一行是一个词，每个词的大小不超过 16 B，内存大小限制是 1MB，要求返回频数最高的 100 个词(Top 100)。

**解答思路**

采用分治策略，逐步读取遍历文件中的每个单词 x，执行 `hash(x) % 5000`，将结果为 i 的单词存放到文件 ai 中，这样我们可以得到 5000 个小文件。如果这个小文件过大的话，可以对这个小文件继续进行拆分。

用 HashMap 统计每个小文件中出现频率最高的的 100 个单词。维护一个小顶堆来找出所有词中频率最高的 100 个。具体方法：构建大小为 100 的小顶堆，依次遍历每个小文件的 TOP100，如果遍历到的次出现的次数大于对顶的词，则用新词替换并重新调整堆，遍历结束后，小顶堆上的词就是 TOP 100.

## 3 如何找出某一天访问百度网站最多的 IP？

**题目描述**

现有海量日志数据保存在一个超大文件中，该文件无法直接读入内存，要求从中提取某天访问百度次数最多的那个 IP。

**解答思路**

采用分治策略，逐步读取遍历文件中的每个 IP，计算 hash(IP) % 1000，将结果为 i 的 url 存放到文件 ai 中，这样就可以得到 1000 个小文件。

使用 HashMap 统计出每个小文件中出现次数最多的IP，遍历所有小文件得到这个次数最多的 IP。

## 4 如何在大量的数据中找出不重复的整数？

## 5 如何在大量的数据中判断一个数是否存在？

## 6 如何查询最热门的查询串？

## 7 如何统计不同电话号码的个数？

## 8 如何从 5 亿个数中找出中位数？

## 9 如何按照 query 的频度排序？

## 10 如何找出排名前 500 的数？

## 11 讲讲大数据中 TopK 问题的常用套路？
